# -*- coding: utf-8 -*-
"""
SOTA æŒ‡æ ‡è®¡ç®—
PRD 5.2 å®ç°

ç‰¹æ€§:
- RankIC (Spearman)
- ICIR
- åˆ†ç»„å•è°ƒæ€§
- å¤šå¤´è¶…é¢æ”¶ç›Š
"""

import numpy as np
import pandas as pd
from scipy.stats import spearmanr, pearsonr
from typing import Dict, List, Tuple, Optional

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

from config.config import Config
from utils.logger import get_logger

logger = get_logger("Metrics")


class SOTAMetrics:
    """
    SOTA æŒ‡æ ‡è®¡ç®—å™¨
    
    è®¡ç®—:
    - Rank IC
    - ICIR
    - åˆ†ç»„å•è°ƒæ€§
    - å¤šå¤´è¶…é¢
    """
    
    def __init__(self, n_groups: int = 10):
        """
        åˆå§‹åŒ–
        
        Args:
            n_groups: åˆ†ç»„æ•°é‡
        """
        self.n_groups = n_groups
        self.results: Dict = {}
    
    def calculate_rank_ic(
        self,
        pred: np.ndarray,
        target: np.ndarray
    ) -> float:
        """
        è®¡ç®— Rank IC (Spearman Correlation)
        
        Args:
            pred: é¢„æµ‹å€¼
            target: çœŸå®æ”¶ç›Š
        
        Returns:
            Rank IC
        """
        try:
            ic, _ = spearmanr(pred, target)
            return ic if not np.isnan(ic) else 0.0
        except:
            return 0.0
    
    def calculate_ic(
        self,
        pred: np.ndarray,
        target: np.ndarray
    ) -> float:
        """
        è®¡ç®— IC (Pearson Correlation)
        """
        try:
            ic, _ = pearsonr(pred, target)
            return ic if not np.isnan(ic) else 0.0
        except:
            return 0.0
    
    def calculate_icir(
        self,
        daily_ics: List[float]
    ) -> float:
        """
        è®¡ç®— ICIR (IC / ICæ ‡å‡†å·®)
        
        Args:
            daily_ics: æ¯æ—¥ IC åˆ—è¡¨
        
        Returns:
            ICIR
        """
        if not daily_ics:
            return 0.0
        
        daily_ics = np.array(daily_ics)
        mean_ic = np.mean(daily_ics)
        std_ic = np.std(daily_ics)
        
        if std_ic < 1e-8:
            return 0.0
        
        return mean_ic / std_ic
    
    def calculate_group_returns(
        self,
        pred: np.ndarray,
        target: np.ndarray,
        n_groups: int = None
    ) -> Dict:
        """
        è®¡ç®—åˆ†ç»„æ”¶ç›Š (åˆ†ä½æ•°)
        
        Args:
            pred: é¢„æµ‹å€¼
            target: çœŸå®æ”¶ç›Š
            n_groups: åˆ†ç»„æ•°
        
        Returns:
            åˆ†ç»„æ”¶ç›Šå­—å…¸
        """
        n_groups = n_groups or self.n_groups
        
        # æŒ‰é¢„æµ‹å€¼åˆ†ç»„
        try:
            groups = pd.qcut(pred, q=n_groups, labels=False, duplicates='drop')
        except:
            return {}
        
        group_returns = {}
        for g in range(n_groups):
            mask = groups == g
            if mask.sum() > 0:
                group_returns[f'G{g+1}'] = np.mean(target[mask])
        
        return group_returns

    @staticmethod
    def calculate_group_returns(
        pred: np.ndarray,
        target: np.ndarray,
        n_groups: int = 5
    ) -> Dict[str, float]:
        """
        è®¡ç®—åˆ†å±‚å›æµ‹æ”¶ç›Š
        """
        df = pd.DataFrame({'pred': pred, 'target': target})
        df['group'] = pd.qcut(df['pred'], n_groups, labels=False, duplicates='drop')
        
        group_ret = df.groupby('group')['target'].mean()
        
        # å•è°ƒæ€§å¾—åˆ† (Spearman rank correlation)
        from scipy.stats import spearmanr
        monotone_score, _ = spearmanr(group_ret.index, group_ret.values)
        
        return {
            'top_group_ret': group_ret.iloc[-1] if not group_ret.empty else 0,
            'bottom_group_ret': group_ret.iloc[0] if not group_ret.empty else 0,
            'spread': group_ret.iloc[-1] - group_ret.iloc[0] if len(group_ret) > 1 else 0,
            'monotone_score': monotone_score
        }

    @staticmethod
    def calculate_alpha_beta(
        strategy_returns: pd.Series,
        benchmark_returns: pd.Series,
        risk_free_rate: float = 0.03
    ) -> Dict[str, float]:
        """
        è®¡ç®— Alpha å’Œ Beta
        """
        if len(strategy_returns) != len(benchmark_returns):
            common_idx = strategy_returns.index.intersection(benchmark_returns.index)
            strategy_returns = strategy_returns.loc[common_idx]
            benchmark_returns = benchmark_returns.loc[common_idx]
            
        if len(strategy_returns) < 2:
            return {'alpha': 0.0, 'beta': 0.0}
            
        # å¹´åŒ–æ— é£é™©æ”¶ç›Šç‡è½¬ä¸ºæ—¥åº¦
        rf_daily = (1 + risk_free_rate) ** (1/252) - 1
        
        # åæ–¹å·®å’Œæ–¹å·®
        matrix = np.cov(strategy_returns, benchmark_returns)
        beta = matrix[0, 1] / matrix[1, 1] if matrix[1, 1] != 0 else 1.0
        
        # Alpha (Jensen's Alpha)
        alpha = (strategy_returns.mean() - rf_daily) - beta * (benchmark_returns.mean() - rf_daily)
        
        return {
            'alpha': alpha * 252,  # å¹´åŒ– Alpha
            'beta': beta
        }

    @staticmethod
    def calculate_advanced_metrics(
        strategy_returns: pd.Series,
        benchmark_returns: pd.Series = None
    ) -> Dict[str, float]:
        """
        è®¡ç®—é«˜çº§é‡‘èæŒ‡æ ‡
        """
        metrics = {}
        
        # åŸºç¡€æŒ‡æ ‡
        total_ret = (1 + strategy_returns).prod() - 1
        ann_ret = (1 + total_ret) ** (252 / len(strategy_returns)) - 1
        vol = strategy_returns.std() * np.sqrt(252)
        sharpe = ann_ret / (vol + 1e-8)
        
        metrics['annual_return'] = ann_ret
        metrics['volatility'] = vol
        metrics['sharpe_ratio'] = sharpe
        
        # æœ€å¤§å›æ’¤
        cum_ret = (1 + strategy_returns).cumprod()
        running_max = cum_ret.cummax()
        drawdown = (cum_ret - running_max) / running_max
        metrics['max_drawdown'] = drawdown.min()
        
        # Calmar æ¯”ç‡
        metrics['calmar_ratio'] = ann_ret / (abs(metrics['max_drawdown']) + 1e-8)
        
        if benchmark_returns is not None:
            # Alpha / Beta
            ab = SOTAMetrics.calculate_alpha_beta(strategy_returns, benchmark_returns)
            metrics.update(ab)
            
            # ä¿¡æ¯æ¯”ç‡ (Information Ratio)
            active_return = strategy_returns - benchmark_returns
            tracking_error = active_return.std() * np.sqrt(252)
            metrics['information_ratio'] = active_return.mean() * 252 / (tracking_error + 1e-8)
            
            # èƒœç‡ (ç›¸å¯¹äºåŸºå‡†)
            metrics['outperformance_rate'] = (strategy_returns > benchmark_returns).mean()
            
        return metrics
    
    def check_monotonicity(
        self,
        group_returns: Dict
    ) -> Tuple[bool, str]:
        """
        æ£€æŸ¥åˆ†ç»„å•è°ƒæ€§
        
        ç†æƒ³æƒ…å†µ: G1 (Top) > G2 > ... > G10 (Bottom)
        
        Args:
            group_returns: åˆ†ç»„æ”¶ç›Š
        
        Returns:
            (æ˜¯å¦å•è°ƒ, è­¦å‘Šä¿¡æ¯)
        """
        if len(group_returns) < 2:
            return True, ""
        
        values = list(group_returns.values())
        
        # æ£€æŸ¥ä¸¥æ ¼é€’å‡
        is_monotonic = all(values[i] >= values[i+1] for i in range(len(values)-1))
        
        message = ""
        if not is_monotonic:
            # æ‰¾å‡ºè¿åå•è°ƒæ€§çš„ä½ç½®
            violations = []
            for i in range(len(values)-1):
                if values[i] < values[i+1]:
                    violations.append(f"G{i+1} < G{i+2}")
            message = f"Non-monotonic: {', '.join(violations)}"
            logger.warning(f"Model Overfitting: {message}")
        
        return is_monotonic, message
    
    def calculate_long_excess(
        self,
        pred: np.ndarray,
        target: np.ndarray,
        top_pct: float = 0.1
    ) -> float:
        """
        è®¡ç®—å¤šå¤´è¶…é¢æ”¶ç›Š  
        
        Top 10% è‚¡ç¥¨ç›¸å¯¹äºå…¨ä½“çš„è¶…é¢æ”¶ç›Š
        
        Args:
            pred: é¢„æµ‹å€¼
            target: çœŸå®æ”¶ç›Š
            top_pct: å¤´éƒ¨æ¯”ä¾‹
        
        Returns:
            è¶…é¢æ”¶ç›Š
        """
        if len(pred) == 0: return 0.0
        
        # æ‰¾åˆ° top 10% çš„é˜ˆå€¼
        try:
            threshold = np.percentile(pred, 100 * (1 - top_pct))
        except:
            return 0.0
        
        # è®¡ç®—å¤´éƒ¨æ”¶ç›Š
        top_mask = pred >= threshold
        if np.sum(top_mask) == 0: return 0.0
        
        top_return = np.mean(target[top_mask])
        
        # å…¨ä½“å¹³å‡æ”¶ç›Š
        avg_return = np.mean(target)
        
        # è¶…é¢
        excess = top_return - avg_return
        
        return excess

    def calculate_long_short_spread(
        self,
        pred: np.ndarray,
        target: np.ndarray,
        quantile: float = 0.1
    ) -> float:
        """
        è®¡ç®—å¤šç©ºæ”¶ç›Šå·® (Long-Short Spread)
        Top 10% - Bottom 10%
        """
        if len(pred) == 0: return 0.0
        
        try:
            top_thresh = np.percentile(pred, 100 * (1 - quantile))
            bot_thresh = np.percentile(pred, 100 * quantile)
        except:
            return 0.0
            
        top_mask = pred >= top_thresh
        bot_mask = pred <= bot_thresh
        
        if np.sum(top_mask) == 0 or np.sum(bot_mask) == 0: return 0.0
        
        top_ret = np.mean(target[top_mask])
        bot_ret = np.mean(target[bot_mask])
        
        return top_ret - bot_ret

    def calculate_classification_metrics(
        self,
        pred: np.ndarray,
        target: np.ndarray
    ) -> Dict:
        """
        è®¡ç®—åˆ†ç±»æŒ‡æ ‡ (Accuracy, Precision, Recall, F1)
        æ³¨æ„: å‡è®¾ pred > 0 ä¸ºé¢„æµ‹ä¸Šæ¶¨, target > 0 ä¸ºå®é™…ä¸Šæ¶¨
        """
        if len(pred) == 0: return {}
        
        # è½¬æ¢ä¸ºäºŒåˆ†ç±»
        pred_label = (pred > 0).astype(int)
        target_label = (target > 0).astype(int)
        
        # æ··æ·†çŸ©é˜µ
        tp = np.sum((pred_label == 1) & (target_label == 1))
        tn = np.sum((pred_label == 0) & (target_label == 0))
        fp = np.sum((pred_label == 1) & (target_label == 0))
        fn = np.sum((pred_label == 0) & (target_label == 1))
        
        total = len(pred)
        
        accuracy = (tp + tn) / total if total > 0 else 0
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
        
        return {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'confusion_matrix': {'tp': int(tp), 'tn': int(tn), 'fp': int(fp), 'fn': int(fn)}
        }
    
    def evaluate(
        self,
        predictions: pd.DataFrame,
        actuals: pd.DataFrame = None,
        date_col: str = 'date',
        pred_col: str = 'score',
        target_col: str = 'return'
    ) -> Dict:
        """
        å®Œæ•´è¯„ä¼°
        
        Args:
            predictions: é¢„æµ‹ DataFrame (å« date, ts_code, score)
            actuals: çœŸå®æ”¶ç›Š DataFrame (å« date, ts_code, return)
            date_col: æ—¥æœŸåˆ—å
            pred_col: é¢„æµ‹åˆ—å
            target_col: æ”¶ç›Šåˆ—å
        
        Returns:
            è¯„ä¼°ç»“æœ
        """
        # åˆå¹¶é¢„æµ‹å’Œå®é™…å€¼
        if actuals is not None:
            data = predictions.merge(actuals, on=['ts_code', date_col], how='inner')
        else:
            data = predictions
            if target_col not in data.columns:
                logger.error("Missing target column")
                return {}
        
        # æŒ‰æ—¥æœŸè®¡ç®— IC
        daily_ics = []
        daily_rank_ics = []
        daily_group_returns = []
        
        for date, group in data.groupby(date_col):
            pred = group[pred_col].values
            target = group[target_col].values
            
            if len(pred) < 10:
                continue
            
            # IC
            ic = self.calculate_ic(pred, target)
            rank_ic = self.calculate_rank_ic(pred, target)
            
            daily_ics.append(ic)
            daily_rank_ics.append(rank_ic)
            
            # åˆ†ç»„æ”¶ç›Š
            gr = self.calculate_group_returns(pred, target)
            if gr:
                daily_group_returns.append(gr)
        
        # æ±‡æ€»ç»“æœ
        self.results = {
            'mean_ic': np.mean(daily_ics) if daily_ics else 0.0,
            'mean_rank_ic': np.mean(daily_rank_ics) if daily_rank_ics else 0.0,
            'ic_std': np.std(daily_ics) if daily_ics else 0.0,
            'rank_ic_std': np.std(daily_rank_ics) if daily_rank_ics else 0.0,
            'icir': self.calculate_icir(daily_rank_ics),
            'n_days': len(daily_ics)
        }
        
        # å¹³å‡åˆ†ç»„æ”¶ç›Š
        if daily_group_returns:
            avg_group_returns = {}
            for key in daily_group_returns[0].keys():
                values = [gr.get(key, 0) for gr in daily_group_returns]
                avg_group_returns[key] = np.mean(values)
            
            self.results['group_returns'] = avg_group_returns
            
            # å•è°ƒæ€§æ£€æŸ¥
            is_mono, msg = self.check_monotonicity(avg_group_returns)
            self.results['is_monotonic'] = is_mono
            self.results['monotonicity_msg'] = msg
        
        # å¤šå¤´è¶…é¢
        pred = data[pred_col].values
        target = data[target_col].values
        self.results['long_excess'] = self.calculate_long_excess(pred, target)
        
        # å¤šç©ºæ”¶ç›Šå·®
        self.results['long_short_spread'] = self.calculate_long_short_spread(pred, target)
        
        # åˆ†ç±»æŒ‡æ ‡
        cls_metrics = self.calculate_classification_metrics(pred, target)
        self.results.update(cls_metrics)
        
        # SOTA éªŒæ”¶
        self._check_sota_thresholds()
        
        return self.results
    
    def _check_sota_thresholds(self):
        """æ£€æŸ¥æ˜¯å¦è¾¾åˆ° SOTA æ ‡å‡†"""
        warnings = []
        
        if self.results.get('mean_rank_ic', 0) < Config.SOTA_TARGET_IC:
            warnings.append(f"Rank IC ({self.results['mean_rank_ic']:.4f}) < Target ({Config.SOTA_TARGET_IC})")
        
        if self.results.get('icir', 0) < Config.SOTA_TARGET_ICIR:
            warnings.append(f"ICIR ({self.results['icir']:.4f}) < Target ({Config.SOTA_TARGET_ICIR})")
        
        if not self.results.get('is_monotonic', True):
            warnings.append("Non-monotonic group returns detected")
        
        self.results['sota_passed'] = len(warnings) == 0
        self.results['sota_warnings'] = warnings
        
        for w in warnings:
            logger.warning(f"SOTA: {w}")
    
    def generate_report(self) -> str:
        """ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š"""
        r = self.results
        
        report = f"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        DeepAlpha SOTA Metrics Report
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š Information Coefficient
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Mean IC:          {r.get('mean_ic', 0):>10.4f}
Mean Rank IC:     {r.get('mean_rank_ic', 0):>10.4f}
IC Std:           {r.get('ic_std', 0):>10.4f}
ICIR:             {r.get('icir', 0):>10.4f}

ğŸ“ˆ Group Returns
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""
        if 'group_returns' in r:
            for g, ret in r['group_returns'].items():
                report += f"{g}:              {ret*100:>10.2f}%\n"
        
        report += f"""
ğŸ“‰ Risk Metrics
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Long Excess:      {r.get('long_excess', 0)*100:>10.2f}%
Long-Short Spread:{r.get('long_short_spread', 0)*100:>10.2f}%
Monotonicity:     {'âœ“ PASS' if r.get('is_monotonic', True) else 'âœ— FAIL'}

ğŸ¯ Classification Metrics (Accuracy)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Accuracy:         {r.get('accuracy', 0)*100:>10.2f}%
Precision:        {r.get('precision', 0)*100:>10.2f}%
Recall:           {r.get('recall', 0)*100:>10.2f}%
F1-Score:         {r.get('f1_score', 0):>10.4f}

ğŸ¯ SOTA Verification
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Status:           {'âœ“ PASS' if r.get('sota_passed', False) else 'âœ— FAIL'}
"""
        if r.get('sota_warnings'):
            report += "Warnings:\n"
            for w in r['sota_warnings']:
                report += f"  â€¢ {w}\n"
        
        report += "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"
        
        return report


def calculate_metrics(predictions: pd.DataFrame, **kwargs) -> Dict:
    """ä¾¿æ·å‡½æ•°ï¼šè®¡ç®—æŒ‡æ ‡"""
    calculator = SOTAMetrics()
    return calculator.evaluate(predictions, **kwargs)
