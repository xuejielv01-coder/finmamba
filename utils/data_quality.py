# -*- coding: utf-8 -*-
"""
æ•°æ®è´¨é‡ç›‘æ§æ¨¡å—
æ”¹è¿›4ï¼šå®ç°æ•°æ®è´¨é‡Dashboard

åŠŸèƒ½:
- ç›‘æ§ç¼ºå¤±å€¼ã€å¼‚å¸¸å€¼ã€åˆ†å¸ƒå˜åŒ–
- å®ç°æ•°æ®æ¼‚ç§»æ£€æµ‹
- ç”Ÿæˆæ•°æ®è´¨é‡æŠ¥å‘Š
"""

import os
import json
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
import numpy as np
import pandas as pd
from scipy import stats
from collections import defaultdict

import sys
sys.path.insert(0, str(Path(__file__).parent.parent))

from config.config import Config
from utils.logger import get_logger

logger = get_logger("DataQuality")


class DataQualityMetrics:
    """æ•°æ®è´¨é‡æŒ‡æ ‡è®¡ç®—"""
    
    @staticmethod
    def calculate_missing_ratio(df: pd.DataFrame) -> Dict[str, float]:
        """è®¡ç®—æ¯åˆ—çš„ç¼ºå¤±ç‡"""
        return (df.isnull().sum() / len(df)).to_dict()
    
    @staticmethod
    def calculate_outlier_ratio(df: pd.DataFrame, threshold: float = 3.0) -> Dict[str, float]:
        """
        è®¡ç®—æ¯åˆ—çš„å¼‚å¸¸å€¼æ¯”ä¾‹ï¼ˆåŸºäºZ-Scoreï¼‰
        
        Args:
            df: æ•°æ®æ¡†
            threshold: Z-Scoreé˜ˆå€¼
        """
        outlier_ratios = {}
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        
        for col in numeric_cols:
            values = df[col].dropna()
            if len(values) > 0:
                z_scores = np.abs(stats.zscore(values))
                outlier_ratios[col] = (z_scores > threshold).mean()
            else:
                outlier_ratios[col] = 0.0
        
        return outlier_ratios
    
    @staticmethod
    def calculate_statistics(df: pd.DataFrame) -> Dict[str, Dict[str, float]]:
        """è®¡ç®—æ¯åˆ—çš„åŸºç¡€ç»Ÿè®¡é‡"""
        stats_dict = {}
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        
        for col in numeric_cols:
            values = df[col].dropna()
            if len(values) > 0:
                stats_dict[col] = {
                    'mean': float(values.mean()),
                    'std': float(values.std()),
                    'min': float(values.min()),
                    'max': float(values.max()),
                    'median': float(values.median()),
                    'skewness': float(values.skew()) if len(values) > 2 else 0.0,
                    'kurtosis': float(values.kurtosis()) if len(values) > 3 else 0.0,
                    'q1': float(values.quantile(0.25)),
                    'q3': float(values.quantile(0.75)),
                }
            else:
                stats_dict[col] = {}
        
        return stats_dict


class DataDriftDetector:
    """æ•°æ®æ¼‚ç§»æ£€æµ‹å™¨"""
    
    def __init__(self, reference_window: int = 30, threshold: float = 0.05):
        """
        åˆå§‹åŒ–æ¼‚ç§»æ£€æµ‹å™¨
        
        Args:
            reference_window: å‚è€ƒçª—å£å¤§å°ï¼ˆå¤©æ•°ï¼‰
            threshold: æ£€æµ‹é˜ˆå€¼
        """
        self.reference_window = reference_window
        self.threshold = threshold
        self.reference_stats: Dict[str, Dict] = {}
    
    def fit(self, df: pd.DataFrame, feature_cols: List[str]):
        """
        æ‹Ÿåˆå‚è€ƒåˆ†å¸ƒ
        
        Args:
            df: å‚è€ƒæ•°æ®
            feature_cols: ç‰¹å¾åˆ—å
        """
        for col in feature_cols:
            if col in df.columns:
                values = df[col].dropna()
                if len(values) > 0:
                    self.reference_stats[col] = {
                        'mean': float(values.mean()),
                        'std': float(values.std()),
                        'min': float(values.min()),
                        'max': float(values.max()),
                    }
        
        logger.info(f"Data drift detector fitted with {len(self.reference_stats)} features")
    
    def detect(self, df: pd.DataFrame) -> Dict[str, Dict]:
        """
        æ£€æµ‹æ•°æ®æ¼‚ç§»
        
        Args:
            df: å½“å‰æ•°æ®
            
        Returns:
            æ¼‚ç§»æ£€æµ‹ç»“æœ
        """
        drift_results = {}
        
        for col, ref_stats in self.reference_stats.items():
            if col not in df.columns:
                continue
            
            values = df[col].dropna()
            if len(values) == 0:
                continue
            
            current_mean = float(values.mean())
            current_std = float(values.std())
            
            # è®¡ç®—å‡å€¼æ¼‚ç§»ï¼ˆä½¿ç”¨æ ‡å‡†åŒ–å·®å¼‚ï¼‰
            if ref_stats['std'] > 1e-10:
                mean_drift = abs(current_mean - ref_stats['mean']) / ref_stats['std']
            else:
                mean_drift = 0.0
            
            # è®¡ç®—æ–¹å·®æ¯”
            if ref_stats['std'] > 1e-10:
                std_ratio = current_std / ref_stats['std']
            else:
                std_ratio = 1.0
            
            # KSæ£€éªŒï¼ˆéœ€è¦å‚è€ƒæ•°æ®ï¼‰
            # è¿™é‡Œä½¿ç”¨ç®€åŒ–çš„æ–¹æ³•ï¼šåŸºäºå‡å€¼å’Œæ ‡å‡†å·®
            is_drifted = mean_drift > 2.0 or std_ratio > 2.0 or std_ratio < 0.5
            
            drift_results[col] = {
                'mean_drift': mean_drift,
                'std_ratio': std_ratio,
                'is_drifted': is_drifted,
                'current_mean': current_mean,
                'current_std': current_std,
                'reference_mean': ref_stats['mean'],
                'reference_std': ref_stats['std'],
            }
        
        # ç»Ÿè®¡æ¼‚ç§»ç‰¹å¾æ•°é‡
        n_drifted = sum(1 for r in drift_results.values() if r['is_drifted'])
        logger.info(f"Data drift detection: {n_drifted}/{len(drift_results)} features drifted")
        
        return drift_results


class DataQualityMonitor:
    """æ•°æ®è´¨é‡ç›‘æ§å™¨"""
    
    def __init__(self, storage_dir: Path = None):
        """
        åˆå§‹åŒ–ç›‘æ§å™¨
        
        Args:
            storage_dir: è´¨é‡æŠ¥å‘Šå­˜å‚¨ç›®å½•
        """
        self.storage_dir = storage_dir or Config.DATA_DIR / "quality_reports"
        self.storage_dir.mkdir(parents=True, exist_ok=True)
        
        self.metrics = DataQualityMetrics()
        self.drift_detector = DataDriftDetector()
        
        # å†å²æŠ¥å‘Š
        self.history: List[Dict] = []
        self._load_history()
        
        logger.info(f"Data quality monitor initialized, storage: {self.storage_dir}")
    
    def _load_history(self):
        """åŠ è½½å†å²æŠ¥å‘Š"""
        history_file = self.storage_dir / "history.json"
        if history_file.exists():
            try:
                with open(history_file, 'r', encoding='utf-8') as f:
                    self.history = json.load(f)
                logger.info(f"Loaded {len(self.history)} historical reports")
            except Exception as e:
                logger.warning(f"Failed to load history: {e}")
                self.history = []
    
    def _save_history(self):
        """ä¿å­˜å†å²æŠ¥å‘Š"""
        history_file = self.storage_dir / "history.json"
        try:
            # åªä¿ç•™æœ€è¿‘30å¤©çš„æŠ¥å‘Š
            cutoff = datetime.now() - timedelta(days=30)
            self.history = [
                h for h in self.history 
                if datetime.fromisoformat(h['timestamp']) > cutoff
            ]
            
            with open(history_file, 'w', encoding='utf-8') as f:
                json.dump(self.history, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logger.error(f"Failed to save history: {e}")
    
    def analyze_stock_data(self, ts_code: str, df: pd.DataFrame) -> Dict:
        """
        åˆ†æå•åªè‚¡ç¥¨çš„æ•°æ®è´¨é‡
        
        Args:
            ts_code: è‚¡ç¥¨ä»£ç 
            df: è‚¡ç¥¨æ•°æ®
            
        Returns:
            è´¨é‡æŠ¥å‘Š
        """
        report = {
            'ts_code': ts_code,
            'timestamp': datetime.now().isoformat(),
            'n_rows': len(df),
            'n_cols': len(df.columns),
            'date_range': None,
            'missing_ratios': {},
            'outlier_ratios': {},
            'statistics': {},
            'issues': [],
            'quality_score': 100.0,
        }
        
        if df.empty:
            report['issues'].append("æ•°æ®ä¸ºç©º")
            report['quality_score'] = 0.0
            return report
        
        # æ—¥æœŸèŒƒå›´
        if 'trade_date' in df.columns:
            report['date_range'] = {
                'start': str(df['trade_date'].min()),
                'end': str(df['trade_date'].max()),
            }
        
        # ç¼ºå¤±ç‡
        report['missing_ratios'] = self.metrics.calculate_missing_ratio(df)
        
        # æ£€æŸ¥é«˜ç¼ºå¤±ç‡åˆ—
        high_missing = [
            col for col, ratio in report['missing_ratios'].items() 
            if ratio > 0.1
        ]
        if high_missing:
            report['issues'].append(f"é«˜ç¼ºå¤±ç‡åˆ—: {', '.join(high_missing)}")
            report['quality_score'] -= len(high_missing) * 5
        
        # å¼‚å¸¸å€¼
        report['outlier_ratios'] = self.metrics.calculate_outlier_ratio(df)
        
        # æ£€æŸ¥é«˜å¼‚å¸¸å€¼åˆ—
        high_outlier = [
            col for col, ratio in report['outlier_ratios'].items() 
            if ratio > 0.05
        ]
        if high_outlier:
            report['issues'].append(f"é«˜å¼‚å¸¸å€¼åˆ—: {', '.join(high_outlier)}")
            report['quality_score'] -= len(high_outlier) * 3
        
        # åŸºç¡€ç»Ÿè®¡
        report['statistics'] = self.metrics.calculate_statistics(df)
        
        # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
        if len(df) < 20:
            report['issues'].append(f"æ•°æ®é‡ä¸è¶³: ä»…{len(df)}æ¡")
            report['quality_score'] -= 20
        
        # ç¡®ä¿è´¨é‡åˆ†æ•°åœ¨0-100ä¹‹é—´
        report['quality_score'] = max(0.0, min(100.0, report['quality_score']))
        
        return report
    
    def analyze_batch(self, data_dir: Path = None, sample_size: int = 100) -> Dict:
        """
        æ‰¹é‡åˆ†ææ•°æ®è´¨é‡
        
        Args:
            data_dir: æ•°æ®ç›®å½•
            sample_size: é‡‡æ ·æ•°é‡
            
        Returns:
            æ±‡æ€»æŠ¥å‘Š
        """
        data_dir = data_dir or Config.RAW_DATA_DIR
        
        # è·å–æ‰€æœ‰æ•°æ®æ–‡ä»¶
        files = list(data_dir.glob("*.parquet"))
        
        if len(files) > sample_size:
            import random
            files = random.sample(files, sample_size)
        
        logger.info(f"Analyzing {len(files)} stock data files...")
        
        all_reports = []
        issues_summary = defaultdict(int)
        quality_scores = []
        
        for file_path in files:
            try:
                ts_code = file_path.stem.replace('_', '.')
                df = pd.read_parquet(file_path)
                
                report = self.analyze_stock_data(ts_code, df)
                all_reports.append(report)
                quality_scores.append(report['quality_score'])
                
                for issue in report['issues']:
                    issues_summary[issue] += 1
                    
            except Exception as e:
                logger.warning(f"Failed to analyze {file_path}: {e}")
        
        # æ±‡æ€»æŠ¥å‘Š
        summary = {
            'timestamp': datetime.now().isoformat(),
            'n_stocks_analyzed': len(all_reports),
            'avg_quality_score': float(np.mean(quality_scores)) if quality_scores else 0.0,
            'min_quality_score': float(np.min(quality_scores)) if quality_scores else 0.0,
            'max_quality_score': float(np.max(quality_scores)) if quality_scores else 0.0,
            'issues_summary': dict(issues_summary),
            'n_low_quality': sum(1 for s in quality_scores if s < 70),
            'n_high_quality': sum(1 for s in quality_scores if s >= 90),
        }
        
        # ä¿å­˜æŠ¥å‘Š
        self.history.append(summary)
        self._save_history()
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        report_file = self.storage_dir / f"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump({
                'summary': summary,
                'details': all_reports
            }, f, indent=2, ensure_ascii=False)
        
        logger.info(f"Batch analysis complete. Avg quality score: {summary['avg_quality_score']:.1f}")
        
        return summary
    
    def get_quality_trend(self) -> pd.DataFrame:
        """è·å–è´¨é‡è¶‹åŠ¿æ•°æ®"""
        if not self.history:
            return pd.DataFrame()
        
        df = pd.DataFrame(self.history)
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        df = df.sort_values('timestamp')
        
        return df
    
    def generate_html_report(self, summary: Dict = None) -> str:
        """
        ç”ŸæˆHTMLæ ¼å¼çš„è´¨é‡æŠ¥å‘Š
        
        Args:
            summary: æ±‡æ€»æŠ¥å‘Š
            
        Returns:
            HTMLå­—ç¬¦ä¸²
        """
        if summary is None:
            summary = self.history[-1] if self.history else {}
        
        html = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <meta charset="UTF-8">
            <title>æ•°æ®è´¨é‡æŠ¥å‘Š</title>
            <style>
                body {{
                    font-family: 'Microsoft YaHei', sans-serif;
                    background: #0f0f23;
                    color: #ffffff;
                    padding: 20px;
                }}
                .container {{
                    max-width: 1200px;
                    margin: 0 auto;
                }}
                h1 {{
                    color: #e94560;
                    border-bottom: 2px solid #e94560;
                    padding-bottom: 10px;
                }}
                .card {{
                    background: #1a1a3e;
                    border-radius: 12px;
                    padding: 20px;
                    margin: 15px 0;
                    box-shadow: 0 4px 15px rgba(0,0,0,0.3);
                }}
                .metric {{
                    display: inline-block;
                    width: 200px;
                    text-align: center;
                    padding: 15px;
                    margin: 10px;
                    background: #16213e;
                    border-radius: 8px;
                }}
                .metric-value {{
                    font-size: 28px;
                    font-weight: bold;
                    color: #00c853;
                }}
                .metric-label {{
                    color: #888;
                    font-size: 12px;
                    margin-top: 5px;
                }}
                .issue-item {{
                    background: #2a2a4e;
                    padding: 10px 15px;
                    margin: 5px 0;
                    border-radius: 6px;
                    border-left: 3px solid #ff5252;
                }}
                .good {{ color: #00c853; }}
                .warning {{ color: #ffeb3b; }}
                .bad {{ color: #ff5252; }}
            </style>
        </head>
        <body>
            <div class="container">
                <h1>ğŸ“Š æ•°æ®è´¨é‡ç›‘æ§æŠ¥å‘Š</h1>
                <p>ç”Ÿæˆæ—¶é—´: {summary.get('timestamp', 'N/A')}</p>
                
                <div class="card">
                    <h2>ğŸ“ˆ æ€»ä½“æŒ‡æ ‡</h2>
                    <div class="metric">
                        <div class="metric-value">{summary.get('n_stocks_analyzed', 0)}</div>
                        <div class="metric-label">åˆ†æè‚¡ç¥¨æ•°</div>
                    </div>
                    <div class="metric">
                        <div class="metric-value {'good' if summary.get('avg_quality_score', 0) >= 80 else 'warning' if summary.get('avg_quality_score', 0) >= 60 else 'bad'}">{summary.get('avg_quality_score', 0):.1f}</div>
                        <div class="metric-label">å¹³å‡è´¨é‡åˆ†æ•°</div>
                    </div>
                    <div class="metric">
                        <div class="metric-value good">{summary.get('n_high_quality', 0)}</div>
                        <div class="metric-label">é«˜è´¨é‡æ•°æ®</div>
                    </div>
                    <div class="metric">
                        <div class="metric-value bad">{summary.get('n_low_quality', 0)}</div>
                        <div class="metric-label">ä½è´¨é‡æ•°æ®</div>
                    </div>
                </div>
                
                <div class="card">
                    <h2>âš ï¸ é—®é¢˜æ±‡æ€»</h2>
        """
        
        for issue, count in summary.get('issues_summary', {}).items():
            html += f'<div class="issue-item">{issue}: <strong>{count}</strong> ä¸ªè‚¡ç¥¨</div>\n'
        
        if not summary.get('issues_summary'):
            html += '<p class="good">æš‚æ— å‘ç°é—®é¢˜ âœ“</p>'
        
        html += """
                </div>
            </div>
        </body>
        </html>
        """
        
        return html


class DataQualityDashboard:
    """æ•°æ®è´¨é‡ä»ªè¡¨ç›˜ï¼ˆGUIç»„ä»¶ï¼‰"""
    
    def __init__(self, monitor: DataQualityMonitor = None):
        self.monitor = monitor or DataQualityMonitor()
    
    def get_summary_data(self) -> Dict:
        """è·å–ä»ªè¡¨ç›˜æ•°æ®"""
        summary = self.monitor.history[-1] if self.monitor.history else {}
        trend = self.monitor.get_quality_trend()
        
        return {
            'summary': summary,
            'trend': trend.to_dict() if not trend.empty else {},
            'last_updated': summary.get('timestamp', 'Never'),
        }


# å‘½ä»¤è¡Œå·¥å…·
def run_quality_check():
    """è¿è¡Œæ•°æ®è´¨é‡æ£€æŸ¥"""
    monitor = DataQualityMonitor()
    summary = monitor.analyze_batch(sample_size=50)
    
    print("\n" + "="*60)
    print("ğŸ“Š æ•°æ®è´¨é‡æ£€æŸ¥æŠ¥å‘Š")
    print("="*60)
    print(f"åˆ†æè‚¡ç¥¨æ•°: {summary['n_stocks_analyzed']}")
    print(f"å¹³å‡è´¨é‡åˆ†æ•°: {summary['avg_quality_score']:.1f}")
    print(f"é«˜è´¨é‡æ•°æ®: {summary['n_high_quality']}")
    print(f"ä½è´¨é‡æ•°æ®: {summary['n_low_quality']}")
    print("\né—®é¢˜æ±‡æ€»:")
    for issue, count in summary['issues_summary'].items():
        print(f"  - {issue}: {count}")
    print("="*60)
    
    # ç”ŸæˆHTMLæŠ¥å‘Š
    html = monitor.generate_html_report(summary)
    report_path = monitor.storage_dir / "latest_report.html"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(html)
    print(f"\nè¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")


if __name__ == "__main__":
    run_quality_check()
